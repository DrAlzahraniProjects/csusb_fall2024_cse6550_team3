rail:
  input:
    parameters:
      - name: question
        type: string
      - name: context
        type: string

  output:
    parameters:
      - name: answer
        type: string

  rules:
    - when: contains_prohibited_words(answer)
      then: substitute('Response cannot contain inappropriate language.')
    - when: length(answer) > 500
      then: truncate(answer, 500)
    - when: not has_citations(context)
      then: substitute('Answer could not be verified from reliable sources.')

  functions:
    - name: contains_prohibited_words
      description: Checks if response contains prohibited or inappropriate words.
      expression: "answer.lower().contains_any(['badword1', 'badword2', 'other_unwanted_terms'])"
    - name: has_citations
      description: Checks if the response includes citations from retrieved documents.
      expression: "len(context) > 0"