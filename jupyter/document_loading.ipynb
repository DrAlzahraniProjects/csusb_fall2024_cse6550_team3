{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a830d552-d63c-4c81-8bb2-665178481343",
   "metadata": {},
   "source": [
    "# Documenation for backend/document_loading.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6b413-94a3-4c71-a0f2-3629135b78c4",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "#### Imports\n",
    "\n",
    "- `os` : A standard library module for interacting with the operating system, primarily for file and directory operations.\n",
    "\n",
    "- `FAISS` : A library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "- `HuggingFaceEmbeddings` : A class for generating embeddings using models from Hugging Face's model hub.\n",
    "\n",
    "- `BM25Retriever` : An implementation of the BM25 retrieval algorithm, which ranks documents based on their relevance to a query.\n",
    "\n",
    "- `EnsembleRetriever` : Combines multiple retrieval strategies for improved performance.\n",
    "\n",
    "- `RecursiveCharacterTextSplitter` : A utility for splitting text into smaller chunks for processing.\n",
    "\n",
    "- `PyPDFDirectoryLoader` : A loader for reading and processing PDF documents from a directory.\n",
    "\n",
    "- `tqdm` : Import tqdm for displaying progress bars in loops and iterative processes.\n",
    "\n",
    "#### Configuration Variables\n",
    "\n",
    "- `tqdm.pandas()` : Integrate tqdm with pandas to display progress bars for `DataFrame` operations.\n",
    "\n",
    "- `EMBEDDING_MODEL_NAME = \"Alibaba-NLP/gte-large-en-v1.5\"`\n",
    "\n",
    "- EMBEDDING_MODEL_NAME: A string specifying the name of the embedding model to be used. This particular model is hosted on Hugging Face and is designed for general English text.\n",
    "\n",
    "- `model_kwargs = {'trust_remote_code': True}`\n",
    "\n",
    "- model_kwargs: A dictionary of keyword arguments to pass to the embedding model. In this case, `trust_remote_code` is set to True, allowing the use of remote code execution from the model.\n",
    "\n",
    "#### Embedding Function\n",
    "\n",
    "`EMBEDDING_FUNCTION = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)`\n",
    "\n",
    "- EMBEDDING_FUNCTION: An instance of the `HuggingFaceEmbeddings` class, initialized with the specified model name and any additional keyword arguments. This function will be used to convert text into embeddings for downstream processing, such as similarity search and document retrieval.\n",
    "  \n",
    "#### Process Overview:\n",
    "\n",
    "- Loading Documents: Use `PyPDFDirectoryLoader` to load PDF documents from a specified directory.\n",
    "\n",
    "- Text Splitting: Use `RecursiveCharacterTextSplitter` to split documents into smaller, manageable chunks for processing.\n",
    "\n",
    "- Generating Embeddings: Call `EMBEDDING_FUNCTION` to convert text chunks into embeddings.\n",
    "\n",
    "- Storing and Retrieving: Use `FAISS` for efficient storage of embeddings and to perform similarity searches. Combine with `BM25Retriever` or `EnsembleRetriever` to rank and retrieve relevant documents based on queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b329b26-88f8-49db-a436-35f58a0740b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported and tqdm configured for pandas.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up tqdm for console use\n",
    "tqdm.pandas()\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model_kwargs = {'trust_remote_code': True}\n",
    "EMBEDDING_FUNCTION = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)\n",
    "print(\"Modules imported and tqdm configured for pandas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b049af-e0c8-4ab1-8448-d8987bb68987",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "`load_documents_from_directory`\n",
    "\n",
    "- This function is designed to load PDF documents from a specified directory, split the documents into smaller text chunks based on given parameters, and return those chunks for further processing.\n",
    "  \n",
    "#### Parameters\n",
    "\n",
    "- `document_path (str)` : The path to the directory containing the PDF files. This is a required argument.\n",
    "\n",
    "- `chunk_size (int, optional)`: The size of each text chunk in characters. The default value is 2048. This parameter controls how much text will be included in each chunk.\n",
    "\n",
    "- `chunk_overlap (int, optional)`:The number of overlapping characters between consecutive chunks. The default value is 200. This helps maintain context between chunks and can improve performance in certain applications.\n",
    "\n",
    "- Returns `List of document chunks`: A list containing the text chunks obtained from splitting the loaded documents. Each chunk is a string of text.\n",
    "\n",
    "#### Process overview\n",
    "\n",
    "- Loading Documents: The function prints a message indicating the loading process and the specified document path. It then uses the `PyPDFDirectoryLoader` to load and split the PDF documents found in the given directory.\n",
    "\n",
    "- Creating a Text Splitter: The function initializes a `RecursiveCharacterTextSplitter` using a Tiktoken encoder. This text splitter is configured with the specified `chunk_size` and `chunk_overlap`.\n",
    "\n",
    "- Splitting Documents: Finally, the function splits the loaded documents into smaller chunks using the text splitter and returns the resulting list of document chunks.\n",
    "\n",
    "- `chunks = load_documents_from_directory('/path/to/pdf/directory', chunk_size=1024, chunk_overlap=100)` \n",
    "\n",
    "- This documentation provides a clear and comprehensive understanding of how to use the `load_documents_from_directory` function, its parameters, return value, and internal logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d31b9d-bf00-4b79-bd51-ae894a17066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from path/to/your/pdf/directory...\n",
      "\n",
      "Documents loaded and split into chunks.\n"
     ]
    }
   ],
   "source": [
    "def load_documents_from_directory(\n",
    "    document_path: str, \n",
    "    chunk_size: int = 2048, \n",
    "    chunk_overlap: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    Load PDF documents from a directory and split them into chunks.\n",
    "\n",
    "    Args:\n",
    "        document_path (str): Path to the directory containing PDF files.\n",
    "        chunk_size (int): Size of each text chunk (default: 2048).\n",
    "        chunk_overlap (int): Overlap between chunks (default: 200).\n",
    "\n",
    "    Returns:\n",
    "        List of document chunks.\n",
    "    \"\"\"\n",
    "    print(f\"Loading documents from {document_path}...\\n\")\n",
    "    # Load PDF documents from the specified directory\n",
    "    documents = PyPDFDirectoryLoader(document_path).load_and_split()\n",
    "    # Create a text splitter using tiktoken encoder\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    # Split the documents into chunks\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(\"Documents loaded and split into chunks.\")  # Output message indicating action taken\n",
    "    return chunks\n",
    "\n",
    "# Example function call\n",
    "document_path = \"path/to/your/pdf/directory\"  # Specify the correct path to your PDF directory\n",
    "chunks = load_documents_from_directory(document_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560cbd0-6eae-40e9-a54d-efc6802ee371",
   "metadata": {},
   "source": [
    "### Description:\n",
    "- The class is defined to represent a document with:\n",
    "    - `id` : A unique identifier for the document.\n",
    "    - `page_content` : The main text content of the document.\n",
    "    - `metadata` : An optional dictionary for any additional data related to the document. If not provided, it defaults to an empty dictionary.\n",
    "- `EMBEDDING_MODEL_NAME` : Specifies the name of the embedding model to be used.\n",
    "  \n",
    "- `model_kwargs` : A dictionary containing additional parameters for the embedding model; in this case, it allows for trusting remote code.\n",
    "  \n",
    "- `EMBEDDING_FUNCTION`: Initializes the embedding function using the specified model name and parameters.\n",
    "  \n",
    "- `load_or_create_faiss_vector_store` : This function is responsible for either loading an existing FAISS vector store from disk or creating a new one if it does not exist. It utilizes the FAISS library for efficient similarity search and indexing of document embeddings.\n",
    "  \n",
    "#### Parameters\n",
    "\n",
    "- `documents` : A list of documents to be indexed in the FAISS vector store. These documents should be pre-processed and embedded using the specified embedding function.\n",
    "\n",
    "- `collection_name (str)` : The name of the collection that will be used to name the FAISS index file. This is a required argument that helps identify the specific collection of documents.\n",
    "\n",
    "- `persist_directory (str)` : The directory where the `FAISS` index will be saved or loaded from. This should be a valid directory path on the filesystem.\n",
    "\n",
    "  \n",
    "Returns `FAISS vector store object`:\n",
    "\n",
    "An instance of the FAISS vector store that can be used for similarity search and retrieval of documents based on their embeddings.\n",
    "\n",
    "#### Function Logic\n",
    "\n",
    "1. Determine Index Path:\n",
    "The function constructs the file path for the FAISS index by combining the `persist_directory` and the `collection_name` to create a file name in the format `<collection_name>_faiss_index` .\n",
    "\n",
    "2. Check for Existing Index:\n",
    "    - If the index file exists at the specified path, it attempts to load the existing `FAISS` vector store. A message is printed to indicate that the existing store is being loaded.\n",
    "\n",
    "    - The `FAISS.load_local()` method is called to load the index, with the `allow_dangerous_deserialization` option set to True for compatibility with potentially unsafe serialized data.\n",
    "\n",
    "3. Create New Index:\n",
    "    - If the index file does not exist, a new `FAISS` vector store is created from the provided documents. A message is printed indicating that a new store is being created.\n",
    "    - The `FAISS.from_documents()` method is used to create the index based on the provided document embeddings. The newly created index is then saved to disk using faiss_store.save_local(index_path).\n",
    "      \n",
    "4. Return the Vector Store: Finally, the function returns the FAISS vector store object, whether it was loaded from disk or newly created.\n",
    "`faiss_store = load_or_create_faiss_vector_store(documents, 'my_collection', '/path/to/persist/directory')`\n",
    "\n",
    "    - Ensure that the documents passed to this function are already embedded using the specified embedding function, which should be defined in the same context.\n",
    "    - The persist_directory should be accessible and writable; otherwise, the function may fail to create or save the FAISS index.\n",
    "\n",
    "5. This documentation provides a clear and comprehensive overview of how to use the load_or_create_faiss_vector_store function, including its parameters, return value and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79dadf30-e8ce-4031-a7e4-f072d217e079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS vector store from path/to/persist/directory/example_collection_faiss_index...\n",
      "\n",
      "FAISS vector store loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Define a Document class with id, page_content, and metadata\n",
    "class Document:\n",
    "    def __init__(self, doc_id, page_content, metadata=None):\n",
    "        self.id = doc_id  # Add an id attribute\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata or {}\n",
    "\n",
    "# Assume EMBEDDING_FUNCTION is defined somewhere in your code.\n",
    "# Replace with your actual embedding function as needed.\n",
    "EMBEDDING_MODEL_NAME = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model_kwargs = {'trust_remote_code': True}\n",
    "EMBEDDING_FUNCTION = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)\n",
    "\n",
    "def load_or_create_faiss_vector_store(\n",
    "    documents, \n",
    "    collection_name, \n",
    "    persist_directory\n",
    "):\n",
    "    \"\"\"\n",
    "    Load an existing FAISS vector store or create a new one if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        documents: List of documents to be indexed.\n",
    "        collection_name (str): Name of the collection.\n",
    "        persist_directory (str): Directory to save/load the FAISS index.\n",
    "        \n",
    "    Returns:\n",
    "        FAISS vector store object.\n",
    "    \"\"\"\n",
    "    index_path = os.path.join(persist_directory, f'{collection_name}_faiss_index')\n",
    "    \n",
    "    if os.path.exists(index_path):\n",
    "        # Load existing FAISS index\n",
    "        print(f\"Loading existing FAISS vector store from {index_path}...\\n\")\n",
    "        faiss_store = FAISS.load_local(index_path, embeddings=EMBEDDING_FUNCTION, allow_dangerous_deserialization=True)\n",
    "        print(\"FAISS vector store loaded successfully.\")\n",
    "    else:\n",
    "        # Create new FAISS index\n",
    "        print(f\"Creating new FAISS vector store in {index_path}...\\n\")\n",
    "        faiss_store = FAISS.from_documents(documents, embedding=EMBEDDING_FUNCTION)\n",
    "        faiss_store.save_local(index_path)\n",
    "        print(f\"New FAISS vector store created and saved to {index_path}.\")\n",
    "        print(f\"Number of documents indexed: {len(documents)}.\")\n",
    "        \n",
    "    return faiss_store\n",
    "\n",
    "# Example usage\n",
    "# Replace these with your actual document contents\n",
    "documents = [\n",
    "    Document(doc_id=1, page_content=\"Document 1 content\", metadata={\"source\": \"source1\"}),\n",
    "    Document(doc_id=2, page_content=\"Document 2 content\", metadata={\"source\": \"source2\"})\n",
    "]\n",
    "\n",
    "collection_name = \"example_collection\"\n",
    "persist_directory = \"path/to/persist/directory\"  # Replace with your actual path\n",
    "\n",
    "# Call the function and print the output\n",
    "faiss_store = load_or_create_faiss_vector_store(documents, collection_name, persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52856d2e-72ec-43c4-bd6a-dbcedbb16e5c",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "1. Document Class: Represents a document with an ID, content, and optional metadata.\n",
    "\n",
    "- Attributes:\n",
    "- `id` : Unique identifier for the document.\n",
    "    - `page_content`: Textual content of the document.\n",
    "    - `metadata`: Optional dictionary for additional document information.\n",
    "`doc = Document(doc_id, page_content, metadata)`\n",
    "\n",
    "2. BM25Retriever Class : Retrieves documents using the BM25 ranking algorithm.\n",
    "\n",
    "- `from_documents(documents, search_kwargs)` : Creates a BM25 retriever from a list of documents.\n",
    "- Returns: A message indicating the number of documents and the value of k.\n",
    "`bm25 = BM25Retriever.from_documents(documents, {'k': 5})`\n",
    "\n",
    "3. FakeFAISS Class : Simulates a FAISS vector store for demonstration.\n",
    "- `as_retriever(search_kwargs)`: Returns a vector retriever with specified search parameters.\n",
    "- Returns: A message indicating the value of k.\n",
    "- `vector_retriever = FakeFAISS.as_retriever({'k': 5})`\n",
    "  \n",
    "4. EnsembleRetriever Class : Combines multiple retrievers into a single ensemble for document retrieval.\n",
    "- Attributes:\n",
    "    - retrievers: List of retriever instances.\n",
    "    - weights: List of weights for each retriever.\n",
    "- `ensemble = EnsembleRetriever([bm25, vector_retriever], [0.6, 0.4])`\n",
    "\n",
    "- `get_hybrid_retriever` : This function creates a hybrid retriever that combines the BM25 retrieval method with a vector search using a FAISS vector store. The hybrid retriever allows for improved search performance by leveraging the strengths of both retrieval methods.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- `documents`: A list of documents that will be used by the BM25 retriever. These documents should be pre-processed and in a suitable format for retrieval.\n",
    "\n",
    "- `vector_store`: An instance of a FAISS vector store that will be used for vector-based retrieval. This store should already contain embeddings of the documents.\n",
    "\n",
    "- `k (int)`:The number of documents to retrieve from the combined search. This parameter specifies how many top results will be returned from the hybrid retriever.\n",
    "\n",
    "Returns\n",
    "\n",
    "- `EnsembleRetriever object`: An instance of the `EnsembleRetriever` that combines the BM25 and vector retrievers. This object can be used to perform searches that leverage both retrieval techniques.\n",
    "\n",
    "#### Function Logic\n",
    "\n",
    "- 1. Create BM25 Retriever: The function initializes a BM25 retriever using the provided documents. This is done using the `BM25Retriever.from_documents()` method, with the `search_kwargs` parameter set to retrieve `k` documents.\n",
    "\n",
    "- 2. Create Vector Retriever: A vector retriever is created from the provided FAISS vector store by calling `vector_store.as_retriever()`, also specifying `search_kwargs` to retrieve k documents.\n",
    "\n",
    "- 3. Combine Retrievers:\n",
    "An EnsembleRetriever is instantiated to combine the two retrievers (BM25 and vector) with specified weights. In this case, BM25 is weighted at 0.6 and the vector search at 0.4, allowing for a balanced contribution from both methods.\n",
    "\n",
    "- 4. Return the Hybrid Retriever:\n",
    "The function returns the combined EnsembleRetriever object, which can now be used to perform searches using the hybrid approach.\n",
    "\n",
    "- 5. `hybrid_retriever = get_hybrid_retriever(documents, faiss_store, k=5)`\n",
    "    - The weights assigned to the retrievers in the ensemble can be adjusted based on the specific use case and the performance of each retrieval method.\n",
    "\n",
    "    - Ensure that the FAISS vector store contains the necessary embeddings for the documents prior to using this function.\n",
    "\n",
    "- This documentation provides a clear overview of how to use the `get_hybrid_retriever` function, including its parameters, return value and internal logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b64cb851-0969-4142-ad8f-f94fb791522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever created: EnsembleRetriever with 2 retrievers.\n"
     ]
    }
   ],
   "source": [
    "# Sample Document class for demonstration purposes\n",
    "class Document:\n",
    "    def __init__(self, doc_id, page_content, metadata=None):\n",
    "        self.id = doc_id\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata or {}\n",
    "\n",
    "# Sample BM25Retriever class for demonstration purposes\n",
    "class BM25Retriever:\n",
    "    @staticmethod\n",
    "    def from_documents(documents, search_kwargs):\n",
    "        return f\"BM25 Retriever created with {len(documents)} documents and k={search_kwargs['k']}\"\n",
    "\n",
    "# Sample FAISS Vector Store class for demonstration purposes\n",
    "class FakeFAISS:\n",
    "    @staticmethod\n",
    "    def as_retriever(search_kwargs):\n",
    "        return f\"Vector retriever created with k={search_kwargs['k']}\"\n",
    "\n",
    "# Sample EnsembleRetriever class for demonstration purposes\n",
    "class EnsembleRetriever:\n",
    "    def __init__(self, retrievers, weights):\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EnsembleRetriever with {len(self.retrievers)} retrievers.\"\n",
    "\n",
    "# Define the hybrid retriever function\n",
    "def get_hybrid_retriever(documents, vector_store, k):\n",
    "    \"\"\"\n",
    "    Create a hybrid retriever combining BM25 and vector search.\n",
    "    Args:\n",
    "        documents: List of documents for BM25 retriever.\n",
    "        vector_store: FAISS vector store for vector retriever.\n",
    "        k (int): Number of documents to retrieve.\n",
    "    Returns:\n",
    "        EnsembleRetriever object combining BM25 and vector search.\n",
    "    \"\"\"\n",
    "    # Create BM25 retriever\n",
    "    bm25_retriever = BM25Retriever.from_documents(documents, search_kwargs={'k': k})\n",
    "    # Create vector retriever\n",
    "    vector_retriever = vector_store.as_retriever(search_kwargs={'k': k})\n",
    "    # Combine retrievers with specified weights\n",
    "    fusion_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, vector_retriever],\n",
    "        weights=[0.6, 0.4]\n",
    "    )\n",
    "    return fusion_retriever\n",
    "\n",
    "# Sample documents for testing\n",
    "documents = [\n",
    "    Document(doc_id=1, page_content=\"Document content 1\"),\n",
    "    Document(doc_id=2, page_content=\"Document content 2\"),\n",
    "]\n",
    "\n",
    "# Create a fake vector store\n",
    "vector_store = FakeFAISS()\n",
    "\n",
    "# Set the number of documents to retrieve\n",
    "k = 5\n",
    "\n",
    "# Call the hybrid retriever function and print the output\n",
    "fusion_retriever = get_hybrid_retriever(documents, vector_store, k)\n",
    "print(f\"Hybrid retriever created: {fusion_retriever}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
