{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59a5f1b-adf2-4779-ae6e-1c9370ab24fe",
   "metadata": {},
   "source": [
    "# Documenation for backend/document_loading.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772a3e4-c04b-4600-8e11-f92bcb8b6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"Alibaba-NLP/gte-large-en-v1.5\"  # Embedding model (https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)\n",
    "model_kwargs = {'trust_remote_code': True}\n",
    "EMBEDDING_FUNCTION = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89315b-e774-477b-91b0-625853c93c30",
   "metadata": {},
   "source": [
    "__Imports__\n",
    "\n",
    "- `os` : A standard library module for interacting with the operating system, primarily for file and directory operations.\n",
    "\n",
    "- `FAISS` : A library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "- `HuggingFaceEmbeddings` : A class for generating embeddings using models from Hugging Face's model hub.\n",
    "\n",
    "- `BM25Retriever` : An implementation of the BM25 retrieval algorithm, which ranks documents based on their relevance to a query.\n",
    "\n",
    "- `EnsembleRetriever` : Combines multiple retrieval strategies for improved performance.\n",
    "\n",
    "- `RecursiveCharacterTextSplitter` : A utility for splitting text into smaller chunks for processing.\n",
    "\n",
    "- `PyPDFDirectoryLoader` : A loader for reading and processing PDF documents from a directory.\n",
    "\n",
    "__Configuration Variables__\n",
    "\n",
    "- `EMBEDDING_MODEL_NAME = \"Alibaba-NLP/gte-large-en-v1.5\"` \n",
    "\n",
    "- `EMBEDDING_MODEL_NAME`: A string specifying the name of the embedding model to be used. This particular model is hosted on Hugging Face and is designed for general English text.\n",
    "\n",
    "`model_kwargs = {'trust_remote_code': True}`\n",
    "\n",
    "```model_kwargs```: A dictionary of keyword arguments to pass to the embedding model. In this case, trust_remote_code is set to True, allowing the use of remote code execution from the model.\n",
    "\n",
    "__Embedding Function__\n",
    "\n",
    "`EMBEDDING_FUNCTION = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)`\n",
    "\n",
    "- EMBEDDING_FUNCTION: An instance of the `HuggingFaceEmbeddings` class, initialized with the specified model name and any additional keyword arguments. This function will be used to convert text into embeddings for downstream processing, such as similarity search and document retrieval.\n",
    "\n",
    "_Process Overview:_\n",
    "\n",
    "1. Loading Documents: Use `PyPDFDirectoryLoader` to load PDF documents from a specified directory.\n",
    "\n",
    "2. Text Splitting: Use `RecursiveCharacterTextSplitter` to split documents into smaller, manageable chunks for processing.\n",
    "\n",
    "3. Generating Embeddings: Call `EMBEDDING_FUNCTION` to convert text chunks into embeddings.\n",
    "\n",
    "4. Storing and Retrieving: Use `FAISS` for efficient storage of embeddings and to perform similarity searches. Combine with `BM25Retriever` or `EnsembleRetriever` to rank and retrieve relevant documents based on queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519c3bd-e035-45fb-a93e-901914571afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_from_directory(\n",
    "\tdocument_path: str, \n",
    "\tchunk_size: int = 2048, \n",
    "\tchunk_overlap: int = 200\n",
    "):\n",
    "\t\"\"\"\n",
    "\tLoad PDF documents from a directory and split them into chunks.\n",
    "\tArgs:\n",
    "\t\tdocument_path (str): Path to the directory containing PDF files.\n",
    "\t\tchunk_size (int): Size of each text chunk (default: 2048).\n",
    "\t\tchunk_overlap (int): Overlap between chunks (default: 200).\n",
    "\tReturns:\n",
    "\t\tList of document chunks.\n",
    "\t\"\"\"\n",
    "\tprint(f\"Loading documents from {document_path}...\\n\")\n",
    "\t# Load PDF documents from the specified directory\n",
    "\tdocuments = PyPDFDirectoryLoader(document_path).load_and_split()\n",
    "\t# Create a text splitter using tiktoken encoder\n",
    "\ttext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\t# Split the documents into chunks\n",
    "\treturn text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf5e92-1e7c-4334-b253-59720da1049e",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "```load_documents_from_directory```\n",
    "\n",
    "- This function is designed to load PDF documents from a specified directory, split the documents into smaller text chunks based on given parameters, and return those chunks for further processing.\n",
    "\n",
    "Parameters\n",
    "\n",
    "```document_path (str):```\n",
    "\n",
    "- The path to the directory containing the PDF files. This is a required argument.\n",
    "\n",
    "```chunk_size (int, optional):```\n",
    "\n",
    "- The size of each text chunk in characters. The default value is 2048. This parameter controls how much text will be included in each chunk.\n",
    "\n",
    "```chunk_overlap (int, optional):```\n",
    "\n",
    "- The number of overlapping characters between consecutive chunks. The default value is 200. This helps maintain context between chunks and can improve performance in certain applications.\n",
    "\n",
    "Returns\n",
    "```List of document chunks:```\n",
    "A list containing the text chunks obtained from splitting the loaded documents. Each chunk is a string of text.\n",
    "\n",
    "_Process overview_\n",
    "\n",
    "1. Loading Documents: The function prints a message indicating the loading process and the specified document path. It then uses the ```PyPDFDirectoryLoader``` to load and split the PDF documents found in the given directory.\n",
    "\n",
    "2. Creating a Text Splitter: The function initializes a ```RecursiveCharacterTextSplitter``` using a Tiktoken encoder. This text splitter is configured with the specified ```chunk_size``` and ```chunk_overlap```.\n",
    "\n",
    "3. Splitting Documents: Finally, the function splits the loaded documents into smaller chunks using the text splitter and returns the resulting list of document chunks.\n",
    "\n",
    "```chunks = load_documents_from_directory('/path/to/pdf/directory', chunk_size=1024, chunk_overlap=100)```\n",
    "\n",
    "4. This documentation provides a clear and comprehensive understanding of how to use the ```load_documents_from_directory function```, its parameters, return value, and internal logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eef5a-ef53-44a5-8238-88a6ca69a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_faiss_vector_store(\n",
    "\tdocuments, \n",
    "\tcollection_name, \n",
    "\tpersist_directory\n",
    "):\n",
    "    \"\"\"\n",
    "    Load an existing FAISS vector store or create a new one if it doesn't exist.\n",
    "    Args:\n",
    "        documents: List of documents to be indexed.\n",
    "        collection_name (str): Name of the collection.\n",
    "        persist_directory (str): Directory to save/load the FAISS index.\n",
    "    Returns:\n",
    "        FAISS vector store object.\n",
    "    \"\"\"\n",
    "    index_path = os.path.join(persist_directory, f'{collection_name}_faiss_index')\n",
    "    if os.path.exists(index_path):\n",
    "        # Load existing FAISS index\n",
    "        print(f\"Loading existing FAISS vector store from {index_path}...\\n\")\n",
    "        faiss_store = FAISS.load_local(index_path, embeddings=EMBEDDING_FUNCTION, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        # Create new FAISS index\n",
    "        print(f\"Creating new FAISS vector store in {index_path}...\\n\")\n",
    "        faiss_store = FAISS.from_documents(documents, embedding=EMBEDDING_FUNCTION)\n",
    "        faiss_store.save_local(index_path)\n",
    "    return faiss_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407ae86-8c40-4a46-81f7-85611f64378b",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "```load_or_create_faiss_vector_store```\n",
    "- This function is responsible for either loading an existing FAISS vector store from disk or creating a new one if it does not exist. It utilizes the FAISS library for efficient similarity search and indexing of document embeddings.\n",
    "\n",
    "Parameters\n",
    "\n",
    "```documents:```\n",
    "\n",
    "- A list of documents to be indexed in the FAISS vector store. These documents should be pre-processed and embedded using the specified embedding function.\n",
    "\n",
    "```collection_name (str):```\n",
    "\n",
    "- The name of the collection that will be used to name the FAISS index file. This is a required argument that helps identify the specific collection of documents.\n",
    "\n",
    "```persist_directory (str):```\n",
    "\n",
    "- The directory where the FAISS index will be saved or loaded from. This should be a valid directory path on the filesystem.\n",
    "\n",
    "Returns\n",
    "```FAISS vector store object:```\n",
    "- An instance of the FAISS vector store that can be used for similarity search and retrieval of documents based on their embeddings.\n",
    "\n",
    "Function Logic\n",
    "\n",
    "1. Determine Index Path:\n",
    "\n",
    "- The function constructs the file path for the FAISS index by combining the ```persist_directory``` and the ```collection_name``` to create a file name in the format ```<collection_name>_faiss_index```.\n",
    "\n",
    "2. Check for Existing Index:\n",
    "\n",
    "- If the index file exists at the specified path, it attempts to load the existing FAISS vector store. A message is printed to indicate that the existing store is being loaded.\n",
    "- The ```FAISS.load_local()``` method is called to load the index, with the ```allow_dangerous_deserialization``` option set to ```True``` for compatibility with potentially unsafe serialized data.\n",
    "\n",
    "3. Create New Index:\n",
    "\n",
    "- If the index file does not exist, a new FAISS vector store is created from the provided documents. A message is printed indicating that a new store is being created.\n",
    "- The ```FAISS.from_documents()``` method is used to create the index based on the provided document embeddings. The newly created index is then saved to disk using ```faiss_store.save_local(index_path)```.\n",
    "\n",
    "4. Return the Vector Store: Finally, the function returns the FAISS vector store object, whether it was loaded from disk or newly created.\n",
    "\n",
    "```faiss_store = load_or_create_faiss_vector_store(documents, 'my_collection', '/path/to/persist/directory')```\n",
    "\n",
    "- Ensure that the documents passed to this function are already embedded using the specified embedding function, which should be defined in the same context.\n",
    "- The persist_directory should be accessible and writable; otherwise, the function may fail to create or save the FAISS index.\n",
    "\n",
    "5. This documentation provides a clear and comprehensive overview of how to use the ```load_or_create_faiss_vector_store function```, including its parameters, return value and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c494e-a7bc-4ebe-8914-57707dd3fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_retriever(documents, vector_store, k):\n",
    "\t\"\"\"\n",
    "\tCreate a hybrid retriever combining BM25 and vector search.\n",
    "\tArgs:\n",
    "\t\tdocuments: List of documents for BM25 retriever.\n",
    "\t\tvector_store: FAISS vector store for vector retriever.\n",
    "\t\tk (int): Number of documents to retrieve.\n",
    "\tReturns:\n",
    "\t\tEnsembleRetriever object combining BM25 and vector search.\n",
    "\t\"\"\"\n",
    "\t# Create BM25 retriever\n",
    "\tbm25_retriever = BM25Retriever.from_documents(documents, search_kwargs={'k': k})\n",
    "\t# Create vector retriever\n",
    "\tvector_retriever = vector_store.as_retriever(search_kwargs={'k': k})\n",
    "\t# Combine retrievers with specified weights\n",
    "\tfusion_retriever = EnsembleRetriever(\n",
    "\t\tretrievers=[bm25_retriever, vector_retriever],\n",
    "\t\tweights=[0.6, 0.4]\n",
    "\t)\n",
    "\treturn fusion_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25a3b9-ada9-4278-8451-6cdab8ad6c75",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "```get_hybrid_retriever```\n",
    "- This function creates a hybrid retriever that combines the BM25 retrieval method with a vector search using a FAISS vector store. The hybrid retriever allows for improved search performance by leveraging the strengths of both retrieval methods.\n",
    "\n",
    "Parameters\n",
    "\n",
    "```documents```:\n",
    "\n",
    "- A list of documents that will be used by the BM25 retriever. These documents should be pre-processed and in a suitable format for retrieval.\n",
    "\n",
    "```vector_store```:\n",
    "\n",
    "- An instance of a FAISS vector store that will be used for vector-based retrieval. This store should already contain embeddings of the documents.\n",
    "\n",
    "```k (int)```:\n",
    "\n",
    "- The number of documents to retrieve from the combined search. This parameter specifies how many top results will be returned from the hybrid retriever.\n",
    "\n",
    "Returns\n",
    "\n",
    "```EnsembleRetriever object:```\n",
    "- An instance of the ```EnsembleRetriever``` that combines the BM25 and vector retrievers. This object can be used to perform searches that leverage both retrieval techniques.\n",
    "\n",
    "_Function Logic_\n",
    "\n",
    "1. Create BM25 Retriever:\n",
    "\n",
    "- The function initializes a BM25 retriever using the provided documents. This is done using the ```BM25Retriever.from_documents()``` method, with the ```search_kwargs``` parameter set to retrieve ```k``` documents.\n",
    "\n",
    "2. Create Vector Retriever:\n",
    "\n",
    "- A vector retriever is created from the provided FAISS vector store by calling ```vector_store.as_retriever()```, also specifying ```search_kwargs``` to retrieve ```k``` documents.\n",
    "\n",
    "3. Combine Retrievers:\n",
    "\n",
    "- An EnsembleRetriever is instantiated to combine the two retrievers (BM25 and vector) with specified weights. In this case, BM25 is weighted at 0.6 and the vector search at 0.4, allowing for a balanced contribution from both methods.\n",
    "\n",
    "4. Return the Hybrid Retriever:\n",
    "\n",
    "- The function returns the combined EnsembleRetriever object, which can now be used to perform searches using the hybrid approach.\n",
    "\n",
    "```\n",
    "hybrid_retriever = get_hybrid_retriever(documents, faiss_store, k=5)\n",
    "```\n",
    "\n",
    "- The weights assigned to the retrievers in the ensemble can be adjusted based on the specific use case and the performance of each retrieval method.\n",
    "- Ensure that the FAISS vector store contains the necessary embeddings for the documents prior to using this function.\n",
    "\n",
    "5. This documentation provides a clear overview of how to use the ```get_hybrid_retriever function```, including its parameters, return value and internal logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
