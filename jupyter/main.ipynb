{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textbook Chatbot \n",
    "\n",
    "The Textbook Chatbot project for CSE 6550 is designed to assist with queries related to the textbook.\"Software Engineering: A Practitioner's Approach.\" The chatbot serves as an educational tool, helping users by providing information, answering questions, and possibly retrieving content from the textbook.\n",
    "\n",
    "## Tabel of contents \n",
    "\n",
    "-- write the contents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.15)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: langchain-mistralai in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.12)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.2.36)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.1.122)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-mistralai) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse<1,>=0.3.1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-mistralai) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15.1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-mistralai) (0.19.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-huggingface) (0.24.5)\n",
      "INFO: pip is looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-huggingface\n",
      "  Obtaining dependency information for langchain-huggingface from https://files.pythonhosted.org/packages/9d/f8/77a303ddc492f6eed8bf0979f2bc6db4fa6eb1089c5e9f0f977dd87bc9c2/langchain_huggingface-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Obtaining dependency information for langchain-huggingface from https://files.pythonhosted.org/packages/19/0a/5c3c0fbed6a0c82949e72950f0b11c5c9b6f7eb7cf2d208df7a90f36d481/langchain_huggingface-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_huggingface-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Obtaining dependency information for langchain-huggingface from https://files.pythonhosted.org/packages/39/ce/ad7f50a6289cf562747df9a966b4d60a848571db2e57ad8d00dca2478096/langchain_huggingface-0.0.3-py3-none-any.whl.metadata\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-huggingface) (2.6.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-huggingface) (4.44.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.6.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.8.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.19)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.3.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain) (2.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.2)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\pavan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pavan\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.1)\n",
      "Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "  Attempting uninstall: langchain-huggingface\n",
      "    Found existing installation: langchain-huggingface 0.1.0\n",
      "    Uninstalling langchain-huggingface-0.1.0:\n",
      "      Successfully uninstalled langchain-huggingface-0.1.0\n",
      "Successfully installed langchain-huggingface-0.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#installing the libraries \n",
    "!pip install langchain langchain_community langchain-mistralai langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for interacting with vector stores, \n",
    "# retrieving relevant information from text data, and loading documents\n",
    "import os\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARNING: Could not find module 'C:\\Users\\pavan\\AppData\\Roaming\\Python\\Python310\\site-packages\\xformers\\_C.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "Need to compile C++ extensions to get sparse attention suport. Please run python setup.py build develop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find module 'C:\\Users\\pavan\\AppData\\Roaming\\Python\\Python310\\site-packages\\xformers\\_C.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n"
     ]
    }
   ],
   "source": [
    "# document loading \n",
    "EMBEDDING_MODEL_NAME = \"Alibaba-NLP/gte-large-en-v1.5\"  # Embedding model (https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)\n",
    "model_kwargs = {'trust_remote_code': True}\n",
    "EMBEDDING_FUNCTION = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)\n",
    "\n",
    "def load_documents_from_directory(\n",
    "\tdocument_path: str, \n",
    "\tchunk_size: int = 2048, \n",
    "\tchunk_overlap: int = 200\n",
    "):\n",
    "\t\"\"\"\n",
    "\tLoad PDF documents from a directory and split them into chunks.\n",
    "\tArgs:\n",
    "\t\tdocument_path (str): Path to the directory containing PDF files.\n",
    "\t\tchunk_size (int): Size of each text chunk (default: 2048).\n",
    "\t\tchunk_overlap (int): Overlap between chunks (default: 200).\n",
    "\tReturns:\n",
    "\t\tList of document chunks.\n",
    "\t\"\"\"\n",
    "\tprint(f\"Loading documents from {document_path}...\")\n",
    "\t# Load PDF documents from the specified directory\n",
    "\tdocuments = PyPDFDirectoryLoader(document_path).load_and_split()\n",
    "\t# Create a text splitter using tiktoken encoder\n",
    "\ttext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\t# Split the documents into chunks\n",
    "\treturn text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "def load_or_create_faiss_vector_store(\n",
    "\tdocuments,\n",
    "\tpersist_directory,\n",
    "\tcollection_name=\"collection\"\n",
    "):\n",
    "\t\"\"\"\n",
    "\tLoad an existing FAISS vector store or create a new one if it doesn't exist.\n",
    "\tArgs:\n",
    "\t\t\tdocuments: List of documents to be indexed.\n",
    "\t\t\tcollection_name (str): Name of the collection.\n",
    "\t\t\tpersist_directory (str): Directory to save/load the FAISS index.\n",
    "\tReturns:\n",
    "\t\t\tFAISS vector store object.\n",
    "\t\"\"\"\n",
    "\tindex_path = os.path.join(persist_directory, f'{collection_name}')\n",
    "\tif os.path.exists(index_path):\n",
    "\t\t# Load existing FAISS index\n",
    "\t\tprint(f\"Loading existing FAISS vector store from {index_path}...\\n\")\n",
    "\t\tfaiss_store = FAISS.load_local(\n",
    "\t\t\tindex_path, \n",
    "\t\t\tembeddings=EMBEDDING_FUNCTION, \n",
    "\t\t\tallow_dangerous_deserialization=True\n",
    "\t\t)\n",
    "\telse:\n",
    "\t\t# Create new FAISS index\n",
    "\t\tprint(f\"Creating new FAISS vector store in {index_path}...\\n\")\n",
    "\t\tfaiss_store = FAISS.from_documents(\n",
    "\t\t\tdocuments, \n",
    "\t\t\tembedding=EMBEDDING_FUNCTION\n",
    "\t\t)\n",
    "\t\tfaiss_store.save_local(index_path)\n",
    "\treturn faiss_store\n",
    "\n",
    "def similarity_search(\n",
    "\tquestion,\n",
    "\tvector_store,\n",
    "\tk,\n",
    "\tdistance_threshold = 420.0\n",
    "):\n",
    "\t\"\"\"\n",
    "\tGet top k most similar documents using FAISS vector store.\n",
    "\tArgs:\n",
    "\t\tquestion: The user question\n",
    "\t\tvector_store: FAISS vector store\n",
    "\t\tk: Number of documents to return\n",
    "\t\tdistance_threshold: Maximum distance score to include document\n",
    "\tReturns:\n",
    "\t\tlist[Document]: Top k most similar documents\n",
    "\t\"\"\"\n",
    "\tretrieved_docs = vector_store.similarity_search_with_score(question, k=k)\n",
    "\tfiltered_docs = [doc for doc, score in retrieved_docs if score <= distance_threshold]\n",
    "\treturn filtered_docs\n",
    "\n",
    "def get_hybrid_retriever(documents, vector_store, k):\n",
    "\t\"\"\"\n",
    "\tCreate a hybrid retriever combining BM25 and vector search.\n",
    "\tArgs:\n",
    "\t\tdocuments: List of documents for BM25 retriever.\n",
    "\t\tvector_store: FAISS vector store for vector retriever.\n",
    "\t\tk (int): Number of documents to retrieve.\n",
    "\tReturns:\n",
    "\t\tEnsembleRetriever object combining BM25 and vector search.\n",
    "\t\"\"\"\n",
    "\t# Create BM25 retriever\n",
    "\tbm25_retriever = BM25Retriever.from_documents(\n",
    "\t\tdocuments, \n",
    "\t\tk = 0\n",
    "\t)\n",
    "\t# Create vector retriever\n",
    "\tvector_retriever = vector_store.as_retriever(\n",
    "\t\tsearch_type=\"similarity\",\n",
    "\t\tsearch_kwargs={\n",
    "\t\t\t'k': k,\n",
    "\t\t}\n",
    "\t)\n",
    "\t# Combine retrievers with specified weights\n",
    "\tfusion_retriever = EnsembleRetriever(\n",
    "\t\tretrievers=[bm25_retriever, vector_retriever],\n",
    "\t\tweights=[0.2, 0.8]\n",
    "\t)\n",
    "\treturn fusion_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template\n",
    "\n",
    "#### Description::\n",
    "\n",
    "- Imports `ChatPromptTemplate` : Facilitates structured conversation prompts for efficient chatbot interactions.\n",
    "\n",
    "- Defines system instructions: Establishes rules for accurate, concise responses about software engineering.\n",
    "\n",
    "- Limits response length: Restricts answers to 256 tokens for user clarity.\n",
    "\n",
    "- Clarifies chatbot identity: Ensures users know they are interacting with a chatbot.\n",
    "\n",
    "- Encourages clarification requests: Promotes seeking additional information for ambiguous or unclear questions.\n",
    "\n",
    "- Creates prompt template: Structures the conversation flow between chatbot and user effectively.\n",
    "\n",
    "- Describes chatbot function: Provides a clear explanation of the chatbot's purpose and scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "\n",
    "# Prompts\n",
    "system_prompt = \"\"\"  # Defines a multi-line string containing system instructions for the chatbot.\n",
    "You are a chatbot answering questions about \"Software Engineering: A Practitioner's Approach\" textbook.  # Specifies the chatbot's context and focus area.\n",
    "\n",
    "1. Always identify yourself as a chatbot, not the textbook.  # Instructs the chatbot to clarify its identity.\n",
    "2. Answer based only on provided context.  # Emphasizes using only the relevant context for responses.\n",
    "3. If unsure, say \"I don't have enough information to answer.\"  # Guides the chatbot on handling uncertainty in answers.\n",
    "4. For unclear questions, ask for clarification.  # Encourages the chatbot to seek more information for ambiguous questions.\n",
    "5. Keep responses under 256 tokens.  # Sets a limit on response length for conciseness.\n",
    "6. Don't invent information.  # Instructs the chatbot to refrain from generating unsupported information.\n",
    "7. Use context only if relevant.  # Advises the chatbot to incorporate context judiciously.\n",
    "8. To questions about your purpose, say: \"I'm a chatbot designed to answer questions about the 'Software Engineering: A Practitioner's Approach' textbook.\"  # Provides a standard response for inquiries about the chatbot's function.\n",
    "\n",
    "Be accurate and concise. Answer only what's asked.  # Reinforces the importance of precision and relevance in responses.\n",
    "\"\"\"\n",
    "\n",
    "# Create the chat prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([  # Creates a chat prompt template from the defined messages.\n",
    "    (\"system\", system_prompt),  # Sets the system prompt as the first message.\n",
    "    (\"human\", \"Question: {input}\\n\\nRelevant Context:\\n{context}\"),  # Defines the human user input format.\n",
    "])\n",
    "\n",
    "def get_chatbot_prompt_description():  # Defines a function that returns a description of the chatbot prompt.\n",
    "    return \"Chatbot prompt for answering textbook-related questions.\"  # Returns a brief description of the chatbot's purpose.\n",
    "\n",
    "# Calls the function to get the prompt description.\n",
    "output = get_chatbot_prompt_description()  \n",
    "print(output)  # Prints the description of the chatbot prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment Setup\n",
    "\n",
    "\n",
    "- Imports modules for SWEBOK document retrieval and processing.\n",
    "\n",
    "- Loads environment variables for SWEBOK chatbot configuration.\n",
    "\n",
    "- Loads SWEBOK documents and manages FAISS vector storage.\n",
    "\n",
    "- Creates hybrid retriever for SWEBOK knowledge querying.\n",
    "\n",
    "- Retrieves Mistral API key for chatbot integration.\n",
    "\n",
    "- Handles errors if paths or API keys are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file, overriding any existing values.\n",
    "load_dotenv(override=True)\n",
    "def load_embeddings():\n",
    "    \"\"\"\n",
    "    Load documents and embeddings from FAISS store.\n",
    "\n",
    "    Returns:\n",
    "        retriever: Hybrid retriever for querying SWEBOK-aligned documents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load environment variables, retrieve path to SWEBOK corpus, and check if it's specified.\n",
    "    document_path = os.getenv(\"CORPUS_SOURCE\")\n",
    "    if not document_path:\n",
    "        raise ValueError(\"CORPUS_SOURCE not found in environment variables.\")\n",
    "\n",
    "    # Set directory path for FAISS index persistence, specify number of top relevant documents, load documents from SWEBOK corpus directory, and check if any were loaded.\n",
    "    persist_directory = os.path.join(document_path, \"faiss_indexes\")\n",
    "    top_k = 15\n",
    "    documents = load_documents_from_directory(document_path)\n",
    "    if not documents:\n",
    "        raise ValueError(\"No documents loaded. Please check the document path.\")\n",
    "\n",
    "    # Create or load FAISS vector store for embeddings and top_k retriever, get hybrid retriever for querying SWEBOK documents, and return it.\n",
    "    faiss_store = load_or_create_faiss_vector_store(documents, persist_directory)\n",
    "    retriever = get_hybrid_retriever(documents, faiss_store, top_k)\n",
    "\n",
    "    # Indicate embeddings and retrieval setup completion for SWEBOK chatbot.\n",
    "    print(\"Embeddings and retriever loaded.\")\n",
    "\n",
    "    return retriever\n",
    "\n",
    "def get_api_key():\n",
    "    \"\"\"\n",
    "    Get Mistral API Key from environment.\n",
    "\n",
    "    Returns:\n",
    "        str: The API key for SWEBOK chatbot connection.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load Mistral API key from environment variable, check if it's provided, and return it.\n",
    "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"MISTRAL_API_KEY not found in environment variables.\")\n",
    "\n",
    "    return api_key\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load embeddings for SWEBOK content querying, retrieve API key for SWEBOK chatbot connection, print successful API key retrieval message, and return.\n",
    "        retriever = load_embeddings()\n",
    "        api_key = get_api_key()\n",
    "        print(f\"Successfully retrieved API Key: {api_key}\")\n",
    "    except ValueError as e:\n",
    "        # Output error if loading SWEBOK configuration fails.\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG chain implementation\n",
    "\n",
    "- Function usage: Generates answers using Retrieval-Augmented Generation (RAG) chain\n",
    "\n",
    "- Question logging: Prints the question being processed for debugging\n",
    "\n",
    "- Chain creation: Sets up question-answer and retrieval chains\n",
    "\n",
    "- Response initialization: Initializes a dictionary for storing answers and context\n",
    "\n",
    "- Response streaming: Streams answers and context from the RAG chain\n",
    "\n",
    "- Output structure: Returns complete answer and model name in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function that generates a response in dictionary format.\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "def load_llm_api(model_name):\n",
    "\t\"\"\"\n",
    "\tLoad and configure the Mistral AI LLM.\n",
    "\tReturns:\n",
    "\t\tChatMistralAI: Configured LLM instance.\n",
    "\t\"\"\"\n",
    "\treturn ChatMistralAI(\n",
    "\t\tmodel=model_name,\n",
    "\t\tmistral_api_key=api_key,\n",
    "\t\ttemperature=0.2,\n",
    "\t\tmax_tokens=256,\n",
    "\t\ttop_p=0.4,\n",
    "\t)\n",
    "MODEL_NAME = \"open-mistral-7b\"\n",
    "llm = load_llm_api(MODEL_NAME)\n",
    "\n",
    "def chat_completion_as_dict(question):  \n",
    "    \"\"\"\n",
    "    Generate a response to a given question using the RAG chain,\n",
    "    returning only the answer in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        question (str): The user question to be answered.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the answer and model name.\n",
    "    \"\"\"\n",
    "    print(f\"Running prompt: {question}\")  # Prints the incoming question for debugging purposes.\n",
    "\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)  # Creates a chain for answering questions using the specified model and prompt.\n",
    "    \n",
    "    rag_chain = create_retrieval_chain(retriever, question_answer_chain)  # Creates a retrieval-augmented generation (RAG) chain for enhanced responses.\n",
    "\n",
    "    full_response = {\"answer\": \"\", \"context\": []}  # Initializes a dictionary to hold the final answer and context.\n",
    "\n",
    "    for chunk in rag_chain.stream({\"input\": question}):  # Streams the response from the RAG chain for the provided question.\n",
    "        if \"answer\" in chunk:  # Checks if the current chunk contains an answer.\n",
    "            full_response[\"answer\"] += chunk[\"answer\"]  # Appends the answer to the full_response dictionary.\n",
    "\n",
    "        if \"context\" in chunk:  # Checks if the current chunk contains context information.\n",
    "            full_response[\"context\"].extend(chunk[\"context\"])  # Extends the context list with additional context from the chunk.\n",
    "\n",
    "    \n",
    "    # final_answer = get_answer_with_source(full_response) \n",
    "\n",
    "    remaining_answer = full_response[\"answer\"]  # Extracts the final answer from the full_response dictionary.\n",
    "\n",
    "    # Return the response without sources and context\n",
    "    return {\n",
    "        \"complete_answer\": remaining_answer,  # Returns the complete answer as part of the response.\n",
    "        \"model\": MODEL_NAME  # Returns the name of the model used for generating the answer.\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":  # Ensures the following code runs only if this script is executed directly.\n",
    "    question = \"What are the benefits of Retrieval-Augmented Generation?\"  # Defines a sample question for testing.\n",
    "    \n",
    "    response = chat_completion_as_dict(question)  # Calls the function with the sample question to generate a response.\n",
    "    \n",
    "    print(f\"Response: {response['complete_answer']}\\nModel: {response['model']}\")  # Prints the complete answer and model name."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
